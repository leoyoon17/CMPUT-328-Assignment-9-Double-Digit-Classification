{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_9_eval2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNtHlMR280h9"
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "\n",
        "class MNISTDD(object):\n",
        "    def __init__(self, subset='train', batch_size=64, labeled_percent=0.2, shuffle=True):\n",
        "        X_train, y_train = np.reshape(np.load(\"train_X.npy\"), (55000,64,64,1)), np.load(\"train_Y.npy\")\n",
        "        X_valid, y_valid = np.reshape(np.load(\"valid_X.npy\"), (5000,64,64,1)), np.load(\"valid_Y.npy\")\n",
        "#         X_test, y_test = np.reshape(np.load(\"test_X.npy\"), (10000,64,64,1)), np.load(\"test_Y.npy\")\n",
        "        X_test, y_test = X_train[0:10000], y_train[0:10000]\n",
        "        \n",
        "        \n",
        "        bboxes_train = np.load(\"train_bboxes.npy\")\n",
        "        bboxes_valid = np.load(\"valid_bboxes.npy\")\n",
        "        bboxes_test = np.load(\"test_bboxes.npy\")\n",
        "        \n",
        "        if subset == 'train':\n",
        "            images = X_train\n",
        "            labels = y_train\n",
        "            bboxes = bboxes_train\n",
        "            np.random.seed(100)\n",
        "#             is_labeled = np.zeros((55000, 1))\n",
        "            labeled_images = np.random.permutation(np.arange(55000))[:int(labeled_percent * 55000)]\n",
        "#             is_labeled[labeled_images] = 1\n",
        "            np.random.seed()\n",
        "  \n",
        "        elif subset == 'valid':\n",
        "            images = X_valid\n",
        "            labels = y_valid\n",
        "            bboxes = bboxes_valid\n",
        "#             is_labeled = np.ones((5000, 1))\n",
        "\n",
        "        elif subset == 'test':\n",
        "            images = X_test\n",
        "            labels = y_test\n",
        "            bboxes = bboxes_test\n",
        "       \n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "        self._images = images\n",
        "        self.images = self._images\n",
        "        self._labels = labels\n",
        "        self.labels = self._labels\n",
        "        self._bboxes = bboxes\n",
        "        self.bboxes = self._bboxes\n",
        "#         self._is_labeled = is_labeled\n",
        "#         self.is_labeled = self._is_labeled\n",
        "        self.batch_size = batch_size\n",
        "        self.num_samples = len(self.images)\n",
        "        self.shuffle = shuffle\n",
        "        if self.shuffle:\n",
        "            self.shuffle_samples()\n",
        "        self.next_batch_pointer = 0\n",
        "\n",
        "    def shuffle_samples(self):\n",
        "        image_indices = np.random.permutation(np.arange(self.num_samples))\n",
        "        self.images = self._images[image_indices]\n",
        "        self.labels = self._labels[image_indices]\n",
        "        self.bboxes = self._bboxes[image_indices]\n",
        "#         self.is_labeled = self._is_labeled[image_indices]\n",
        "\n",
        "    def get_next_batch(self):\n",
        "        num_samples_left = self.num_samples - self.next_batch_pointer\n",
        "        if num_samples_left >= self.batch_size:\n",
        "            x_batch = self.images[self.next_batch_pointer:self.next_batch_pointer + self.batch_size]\n",
        "            y_batch = self.labels[self.next_batch_pointer:self.next_batch_pointer + self.batch_size]\n",
        "            batch_bboxes = self.bboxes[self.next_batch_pointer:self.next_batch_pointer + self.batch_size]\n",
        "#             is_labeled_batch = self.is_labeled[self.next_batch_pointer:self.next_batch_pointer + self.batch_size]\n",
        "            self.next_batch_pointer += self.batch_size\n",
        "        else:\n",
        "            x_partial_batch_1 = self.images[self.next_batch_pointer:self.num_samples]\n",
        "            y_partial_batch_1 = self.labels[self.next_batch_pointer:self.num_samples]\n",
        "            bboxes_partial_batch_1 = self.bboxes[self.next_batch_pointer:self.num_samples]\n",
        "#             is_labeled_batch_1 = self.is_labeled[self.next_batch_pointer:self.num_samples]\n",
        "            if self.shuffle:\n",
        "                self.shuffle_samples()\n",
        "            x_partial_batch_2 = self.images[0:self.batch_size - num_samples_left]\n",
        "            y_partial_batch_2 = self.labels[0:self.batch_size - num_samples_left]\n",
        "            bboxes_partial_batch_2 = self.bboxes[0:self.batch_size - num_samples_left]\n",
        "#             is_labeled_batch_2 = self.is_labeled[0:self.batch_size - num_samples_left]\n",
        "            x_batch = np.vstack((x_partial_batch_1, x_partial_batch_2))\n",
        "            y_batch = np.vstack((y_partial_batch_1, y_partial_batch_2))\n",
        "            batch_bboxes = np.vstack((bboxes_partial_batch_1,bboxes_partial_batch_2))\n",
        "#             is_labeled_batch = np.vstack((is_labeled_batch_1, is_labeled_batch_2))\n",
        "            self.next_batch_pointer = self.batch_size - num_samples_left\n",
        "        return x_batch, y_batch, batch_bboxes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYKC1wyjlh6s"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib.layers import flatten\n",
        "from sklearn.utils import shuffle\n",
        "from skimage.draw import polygon\n",
        "\n",
        "\"\"\"Ops part\"\"\"\n",
        "\n",
        "\n",
        "# Reference: https://github.com/openai/improved-gan/blob/master/imagenet/ops.py\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# TODO: Optionally create utility functions for convolution, fully connected layers here\n",
        "def create_weights(shape):\n",
        "  initializer = tf.contrib.layers.xavier_initializer() \n",
        "  return tf.Variable(initializer(shape))\n",
        "\n",
        "def create_biases(size):\n",
        "  return tf.Variable(tf.zeros(size))\n",
        "\n",
        "def conv2d(x,W):\n",
        "#   weight_decay = 1e-4\n",
        "#   regularizer = tf.contrib.layers.12_regularizer(weight_decay)\n",
        "  return tf.nn.conv2d(x,W,strides=[1,1,1,1], padding='SAME')\n",
        "\n",
        "def max_pool(x):\n",
        "  return tf.nn.max_pool(x, ksize=[1,2,2,1],strides=[1,2,2,1], padding='VALID')\n",
        "\n",
        "def conv_layer(input,shape):\n",
        "  W = create_weights(shape)\n",
        "  b = create_biases(shape[3])\n",
        "  return tf.nn.elu(conv2d(input,W) + b)\n",
        "\n",
        "def fc_layer(input,size):\n",
        "  in_size = int(input.get_shape()[1])\n",
        "  W = create_weights([in_size,size])\n",
        "  b = create_biases([size])\n",
        "  return tf.add(tf.matmul(input,W), b)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hMezEhxmR9Y"
      },
      "source": [
        "def classification_net(input_tensor, is_training, dropout_kept_prob):\n",
        "  is_training = tf.convert_to_tensor(is_training, tf.bool)\n",
        "  initializer = tf.contrib.layers.xavier_initializer()\n",
        "  \n",
        "  conv1_filter = 51\n",
        "  conv1_1 = conv_layer(input_tensor, (3,3,1,conv1_filter))\n",
        "#   conv1_2 = conv_layer(conv1_1, (3,3,conv1_filter,conv1_filter))\n",
        "  conv1_pool = max_pool(conv1_1)\n",
        "  \n",
        "  conv2_filter = 51\n",
        "  conv2_1 = conv_layer(conv1_pool, (3,3, conv1_filter,conv2_filter))\n",
        "#   conv2_2 = conv_layer(conv2_1, (3,3, conv2_filter,conv2_filter))\n",
        "  conv2_1_pool = max_pool(conv2_1)\n",
        "  \n",
        "  conv2_3 = conv_layer(conv2_1_pool, (3,3, conv2_filter,conv2_filter))\n",
        "  conv2_4 = conv_layer(conv2_3, (3,3,conv2_filter,conv2_filter))\n",
        "  conv2_pool = max_pool(conv2_4)\n",
        "  \n",
        "  conv3_filter = 51\n",
        "  conv3_1 = conv_layer(conv2_pool, (3,3,conv2_filter, conv3_filter))\n",
        "  conv3_1_pool = max_pool(conv3_1)\n",
        "  \n",
        "  conv3_2 = conv_layer(conv3_1_pool, (3,3,conv3_filter, conv3_filter))\n",
        "  conv3_2_pool = max_pool(conv3_2)\n",
        "  \n",
        "  conv3_3 = conv_layer(conv3_2_pool, (3,3,conv3_filter,conv3_filter))\n",
        "  conv3_pool = max_pool(conv3_3)\n",
        "  \n",
        "  fc0 = flatten(conv3_pool)\n",
        "  \n",
        "  fc0_dropout = tf.nn.dropout(fc0, keep_prob=0.5)\n",
        "  fc_filter = 51\n",
        "  \n",
        "  # Conv\n",
        "  fc4_W = tf.Variable(initializer(shape=(fc_filter,20)), name='fc4_W')\n",
        "  fc4_b = tf.Variable(tf.zeros(20), name='fc2_b')\n",
        "  logits = tf.matmul(fc0,fc4_W) + fc4_b\n",
        "  \n",
        "  # Pool\n",
        "  bfc4_W = tf.Variable(initializer(shape=(fc_filter,8)), name='fc4_W')\n",
        "  bfc4_b = tf.Variable(tf.zeros(8), name='fc2_b')\n",
        "  blogits = tf.matmul(fc0,bfc4_W) + bfc4_b\n",
        "  \n",
        "  return logits, blogits\n",
        "\n",
        "\n",
        "\n",
        "def train():\n",
        "  tf.reset_default_graph()\n",
        "\n",
        "  EPOCHS = 150\n",
        "  BATCH_SIZE = 64\n",
        "  NUM_ITERS = int(55000/BATCH_SIZE * EPOCHS)\n",
        "  print(\"Number of Iterations: \", NUM_ITERS)\n",
        "  \n",
        "  train_set = MNISTDD('train', batch_size=BATCH_SIZE)\n",
        "  valid_set = MNISTDD('valid',shuffle=False)\n",
        "  \n",
        "  X_train, y_train = np.reshape(np.load(\"train_X.npy\"), (55000,64,64,1)), np.load(\"train_Y.npy\")\n",
        "  bboxes_train = np.load(\"train_bboxes.npy\")\n",
        "\n",
        "  \n",
        "  x = tf.placeholder(tf.float32, [None, 64, 64, 1], name='x')\n",
        "  y = tf.placeholder(tf.int32, [None, 2], name='y')\n",
        "  bboxes = tf.placeholder(tf.int32,[None,2,4])\n",
        "  one_hot_y = tf.one_hot(y, depth=10)\n",
        "  \n",
        "  rate = 0.001\n",
        "\n",
        "  logits, blogits = classification_net(x,True,1)\n",
        "  logits = tf.reshape(logits, [-1,2,10])\n",
        "  blogits = tf.reshape(blogits, (-1,2,4))\n",
        "  \n",
        "  prediction = tf.argmax(logits, axis=2)\n",
        "  prediction = tf.contrib.framework.sort(prediction)\n",
        "  bboxes_prediction = blogits\n",
        "\n",
        "  # Regularization Function: Cross Entropy\n",
        "  cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=one_hot_y)\n",
        "  classification_loss = tf.reduce_mean(cross_entropy)\n",
        "  location_loss = tf.losses.mean_squared_error(bboxes,blogits)\n",
        "  loss_operation = tf.reduce_mean(cross_entropy) + location_loss\n",
        "#   loss_operation = tf.reduce_mean(cross_entropy)\n",
        "  \n",
        "  \n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
        "#   grads_and_vars = optimizer.compute_gradients(loss_operation, tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\n",
        "  training_operation = optimizer.minimize(loss_operation)\n",
        "  \n",
        "\n",
        "  correct_prediction = tf.equal(tf.argmax(logits, 2), tf.argmax(one_hot_y, 2))\n",
        "\n",
        "  accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "  saver = tf.train.Saver(max_to_keep=0)\n",
        "  \n",
        "    \n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    X_train, y_train = shuffle(X_train, y_train)\n",
        "    for i in range(NUM_ITERS):\n",
        "      batch_x, batch_y, batch_bboxes = train_set.get_next_batch()\n",
        "      train_op,acc_op = sess.run([training_operation,accuracy_operation], feed_dict={x: batch_x,\n",
        "                                                  y: batch_y,\n",
        "                                                  bboxes: batch_bboxes\n",
        "                                                  })\n",
        "      \n",
        "      if (i + 1) % 1000 == 0 or i == NUM_ITERS - 1:\n",
        "        cls_pred, bbox_pred,cls_loss, bbox_loss= sess.run([prediction, bboxes_prediction,classification_loss,location_loss], feed_dict={x: valid_set.images,y:valid_set.labels,\n",
        "                                                                                             bboxes: valid_set.bboxes})\n",
        "        print(\"Iteration: \", i)\n",
        "        print(\"CLS_LOSS: \", cls_loss)\n",
        "        print(\"BBOX_LOSS: \", bbox_loss)\n",
        "        print(\"train_acc: \",acc_op)\n",
        "#       \n",
        "        evaluation(cls_pred,bbox_pred)\n",
        "        saver.save(sess,'ckpt/assignment9', global_step=i)\n",
        "    \n",
        "    \n",
        "def test():\n",
        "  tf.reset_default_graph()\n",
        "  \n",
        "  test_set = MNISTDD('test', shuffle=False)\n",
        "  \n",
        "  x = tf.placeholder(tf.float32, [None, 64, 64, 1], name='x')\n",
        "  y_pred = tf.placeholder(tf.int32, [None, 2], name='y')\n",
        "  bboxes = tf.placeholder(tf.int32,[None,2,4])\n",
        "  one_hot_y = tf.one_hot(y_pred, depth=10)\n",
        "  \n",
        "  logits, blogits = classification_net(x,False,1)\n",
        "  logits = tf.reshape(logits, [-1,2,10])\n",
        "  blogits = tf.reshape(blogits, (-1,2,4))\n",
        "  saver = tf.train.Saver(max_to_keep=0)\n",
        "  \n",
        "  \n",
        "  cls_prediction = tf.argmax(logits, axis=2)\n",
        "  cls_prediction = tf.contrib.framework.sort(cls_prediction)\n",
        "  bbox_predictions = blogits\n",
        "  \n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    #     saver.restore(sess, tf.train.latest_checkpoint('ckpt'))\n",
        "    saver.restore(sess, './assignment9-128905')\n",
        "    \n",
        "    cls_pred, bbox_pred = sess.run([cls_prediction,bbox_predictions], feed_dict={x: test_set.images[0:5000],\n",
        "                                                                                  y_pred:test_set.labels[0:5000],\n",
        "                                                                                  bboxes: test_set.bboxes[0:5000]\n",
        "                                                             })\n",
        "    \n",
        "    cls_pred2, bbox_pred2 = sess.run([cls_prediction,bbox_predictions], feed_dict={x: test_set.images[5000:10000],\n",
        "                                                                                  y_pred:test_set.labels[5000:10000],\n",
        "                                                                                  bboxes: test_set.bboxes[5000:10000]\n",
        "                                                             })\n",
        "    \n",
        "    cls_pred_final = np.concatenate((cls_pred, cls_pred2))\n",
        "    bbox_pred_final = np.concatenate((bbox_pred, bbox_pred2))\n",
        "#     evaluation(cls_pred, bbox_pred,prefix=\"test\")\n",
        "    evaluation2(cls_pred_final, bbox_pred_final ,prefix=\"test\")  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb3btmXM6Tqv"
      },
      "source": [
        "def compute_classification_acc(pred, gt):\n",
        "  # pred and gt are both\n",
        "  print(\"pred: \", pred.shape)\n",
        "  print(\"gt: \", gt.shape)\n",
        "  assert pred.shape == gt.shape\n",
        "  return (pred == gt).astype(int).sum() / gt.size\n",
        "    \n",
        "    \n",
        "def compute_iou(b_pred,b_gt):\n",
        "  # b_pred: predicted bounding boxes, shape=(n,2,4)\n",
        "  # b_gt: ground truth bounding boxes, shape=(n,2,4)\n",
        "    \n",
        "  n = np.shape(b_gt)[0]\n",
        "  L_pred = np.zeros((64,64))\n",
        "  L_gt = np.zeros((64,64))\n",
        "  iou = 0.0\n",
        "  for i in range(n):\n",
        "    for b in range(2):\n",
        "      rr, cc = polygon([b_pred[i,b,0],b_pred[i,b,0],b_pred[i,b,2],b_pred[i,b,2]],\n",
        "                   [b_pred[i,b,1],b_pred[i,b,3],b_pred[i,b,3],b_pred[i,b,1]],[64,64])\n",
        "      L_pred[rr,cc] = 1\n",
        "\n",
        "      rr, cc = polygon([b_gt[i,b,0],b_gt[i,b,0],b_gt[i,b,2],b_gt[i,b,2]],\n",
        "                      [b_gt[i,b,1],b_gt[i,b,3],b_gt[i,b,3],b_gt[i,b,1]],[64,64])\n",
        "      L_gt[rr,cc] = 1\n",
        "\n",
        "      iou += (1.0/(2*n))*(np.sum((L_pred+L_gt)==2)/np.sum((L_pred+L_gt)>=1))\n",
        "\n",
        "      L_pred[:,:] = 0\n",
        "      L_gt[:,:] = 0\n",
        "    \n",
        "  return iou\n",
        "\n",
        "\n",
        "def evaluation(pred_class, pred_bboxes, prefix=\"valid\"):\n",
        "  # pred_class: Your predicted labels for the 2 digits, shape [N, 2]\n",
        "  # pred_bboxes: Your predicted bboxes for 2 digits, shape [N, 2, 4]\n",
        "  gt_class = np.load(prefix + \"_Y.npy\")\n",
        "  gt_bboxes = np.load(prefix + \"_bboxes.npy\")\n",
        "  acc = compute_classification_acc(pred_class, gt_class)\n",
        "  iou = compute_iou(pred_bboxes, gt_bboxes)\n",
        "  print(f\"Classification Acc: {acc}\")\n",
        "  print(f\"BBoxes IOU: {iou}\")\n",
        "  print(\"===============================\")\n",
        "  \n",
        "def evaluation2(pred_class, pred_bboxes, prefix=\"valid\"):\n",
        "  # pred_class: Your predicted labels for the 2 digits, shape [N, 2]\n",
        "  # pred_bboxes: Your predicted bboxes for 2 digits, shape [N, 2, 4]\n",
        "  gt_class = np.load(\"train\" + \"_Y.npy\")\n",
        "  gt_bboxes = np.load(\"train\" + \"_bboxes.npy\")\n",
        "  \n",
        "  gt_class = gt_class[0:10000]\n",
        "  gt_bboxes = gt_bboxes[0:10000]\n",
        "  acc = compute_classification_acc(pred_class, gt_class)\n",
        "  iou = compute_iou(pred_bboxes, gt_bboxes)\n",
        "  print(f\"Classification Acc: {acc}\")\n",
        "  print(f\"BBoxes IOU: {iou}\")\n",
        "  print(\"===============================\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMvPUkNJpyNr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "bf31763a-788a-4883-fe2d-325403baaeb1"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "  TRAIN = False\n",
        "  if TRAIN:\n",
        "    train()\n",
        "    print(\"Testing...\")\n",
        "    test()\n",
        "  else:\n",
        "    test()\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./assignment9-128905\n",
            "pred:  (10000, 2)\n",
            "gt:  (10000, 2)\n",
            "Classification Acc: 0.949\n",
            "BBoxes IOU: 0.8911935609894861\n",
            "===============================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdAdvytmRVRA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}